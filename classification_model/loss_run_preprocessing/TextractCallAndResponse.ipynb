{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61729416-f5f7-4ba0-99b9-27f96c5499d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06d69ff-7c7a-4980-bd7e-89118283d6c0",
   "metadata": {},
   "source": [
    "### Function to Parse AWS Textract document analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3818d8-31e5-4dfd-8e8b-4735e8cc95e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Textract client\n",
    "textract = boto3.client('textract', region_name='us-east-1')\n",
    "\n",
    "# Get Bucket Name from Environment Variable\n",
    "bucket_name = os.getenv('BUCKET')\n",
    "\n",
    "def startDocumentAnalysis(file_name: str) -> str:\n",
    "    # Start the document analysis job\n",
    "    response = textract.start_document_analysis(\n",
    "        DocumentLocation={\n",
    "            'S3Object': {\n",
    "                'Bucket': bucket_name,\n",
    "                'Name': file_name,\n",
    "            }\n",
    "        },\n",
    "        FeatureTypes=['TABLES'],\n",
    "    )\n",
    "\n",
    "    job_id = response['JobId']\n",
    "    return job_id\n",
    "\n",
    "def extract_tables_from_json(job_id):\n",
    "    # Fetch first page of results\n",
    "    response = textract.get_document_analysis(JobId=job_id)\n",
    "    \n",
    "    # Create tables array to store each table from each page\n",
    "    tables = []\n",
    "    \n",
    "    while True:  # Continue until there are no more pages\n",
    "        # Create a dictionary to map Block Ids to Blocks for faster lookup\n",
    "        block_map = {block['Id']: block for block in response['Blocks']}\n",
    "\n",
    "        with open(f'textract_output_{i}.json', 'w') as json_file:\n",
    "            json.dump(response, json_file, indent=4)  # Save with indentation for readability\n",
    "        i += 1\n",
    "        # Iterate through the blocks in the current response\n",
    "        for block in response.get('Blocks', []):\n",
    "            # If block is a table, traverse each CHILD ID represents a table cell\n",
    "            if block['BlockType'] == 'TABLE':\n",
    "                curr_table = {}  # Initialize a new table for this block\n",
    "                for relationship in block.get('Relationships', []):\n",
    "                    if relationship['Type'] == 'CHILD':\n",
    "                        cell_ids = relationship.get('Ids', [])\n",
    "                        for cell_id in cell_ids:\n",
    "                            cell_block = block_map.get(cell_id)\n",
    "\n",
    "                            if cell_block and cell_block['BlockType'] == 'CELL':\n",
    "                                row = cell_block['RowIndex']\n",
    "                                col = cell_block['ColumnIndex']\n",
    "                                cell_text = ''\n",
    "\n",
    "                                # Get the text from the WORD blocks inside the CELL block\n",
    "                                for rel in cell_block.get('Relationships', []):\n",
    "                                    if rel['Type'] == 'CHILD':\n",
    "                                        for word_id in rel.get('Ids', []):\n",
    "                                            word_block = block_map.get(word_id)\n",
    "                                            if word_block and word_block['BlockType'] == 'WORD':\n",
    "                                                cell_text += word_block['Text'] + ' '\n",
    "                                # Add the cell text to the table dictionary\n",
    "                                if row not in curr_table:\n",
    "                                    curr_table[row] = {}\n",
    "                                curr_table[row][col] = cell_text.strip()\n",
    "                #print(curr_table)\n",
    "                # Append the current table to the tables list\n",
    "                tables.append(curr_table)\n",
    "\n",
    "        # Check for the next token\n",
    "        next_token = response.get('NextToken')\n",
    "        print(next_token)\n",
    "        if not next_token:\n",
    "            break  # Exit the loop if there are no more pages\n",
    "\n",
    "        # Fetch the next page of results\n",
    "        response = textract.get_document_analysis(JobId=job_id, NextToken=next_token)\n",
    "\n",
    "    print(len(tables))\n",
    "    table_dfs = []\n",
    "    for table in tables:\n",
    "        # Convert the extracted table into a DataFrame\n",
    "        table_dfs.append(pd.DataFrame.from_dict(table, orient='index'))\n",
    "    return table_dfs\n",
    "\n",
    "def getDocumentAnalysis(job_id: str):\n",
    "    # Check job status\n",
    "    while True:\n",
    "        response = textract.get_document_analysis(JobId=job_id)\n",
    "        status = response['JobStatus']\n",
    "\n",
    "        if status in ['SUCCEEDED', 'FAILED']:  # If status received, escape loop\n",
    "            break\n",
    "        time.sleep(5)  # Wait before checking again\n",
    "\n",
    "    if status == 'SUCCEEDED':\n",
    "        return extract_tables_from_json(job_id)\n",
    "    else:\n",
    "        print(\"Job failed.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3437a946-b2df-49ec-988a-2037bc07f91b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "response = textract.start_document_analysis(\n",
    "    DocumentLocation={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': 'LenStolerPage3.pdf',\n",
    "        }\n",
    "    },\n",
    "    FeatureTypes=['TABLES'],\n",
    ")\n",
    "job_id = response['JobId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "347c46c9-6d29-4b59-bafa-ed65fe319124",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = 'b1a8ede14bb1550344aaf3862a72f6d50e94bb3c1badc6fc01ceb2e50b9359c4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "545ef3b2-df86-4538-a325-10a77b963983",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 0, Total Blocks: 1000\n",
      "qo+wUWWB68RHs5kgpvznzPtbg5FLfUv9g3MV81d214mrqD2YRDgRB8I2lsAubjHyW/ZDE7h2jUbEGx080pVZHIdR74Z78k+ul4PnnxjO5xzOjunLszQH5oNx6trF5IqW8aRqpvg=\n",
      "Processing page 1, Total Blocks: 782\n",
      "None\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_dfs = getDocumentAnalysis(job_id)\n",
    "len(table_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e039ba9-4413-4f8a-a708-df6ad058b1b9",
   "metadata": {},
   "source": [
    "## Function to Load File Depending on Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c249a2c6-168d-46ca-9ea3-6fea0766e16f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to load file based on its extension\n",
    "def load_file(file_path):\n",
    "    # Get the file extension\n",
    "    file_extension = os.path.splitext(file_path)[1]\n",
    "\n",
    "    # Conditional logic to load the file\n",
    "    if file_extension == '.csv':\n",
    "        # Load CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_extension == '.xlsx':\n",
    "        # Load Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please provide a CSV or XLSX file.\")\n",
    "    \n",
    "    # Use loc to slice the DataFrame up to column 'description' (inclusive)\n",
    "    df = df.loc[:, :'description']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f152cc-05fe-485f-83cd-3c5dc8a75d3d",
   "metadata": {},
   "source": [
    "## Prepare Correct Output Data for Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "15e14f6e-9946-4169-a405-6462ad3afb32",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "# Convert all output files into single dataframe\n",
    "for filename in os.listdir('loss_runs/output'):\n",
    "    f = os.path.join('loss_runs/output', filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        frames.append(load_file(f))\n",
    "\n",
    "# Merge all output dataframes\n",
    "merged_output_frames = pd.concat(frames)\n",
    "merged_output_frames.to_csv('merged_loss_runs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a67f1-5be5-40a7-bfe6-0964316085cc",
   "metadata": {},
   "source": [
    "## Label Input Data if Claim Number Appears in Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "65001bc2-a34c-4e60-aeb7-658c4d747392",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>1</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Sub Coverage</th>\n",
       "      <th>Val ID Description</th>\n",
       "      <th>Claim Number</th>\n",
       "      <th>Date of Loss</th>\n",
       "      <th>Status</th>\n",
       "      <th>Claimant Name</th>\n",
       "      <th>Accident Narrative</th>\n",
       "      <th>Paid Indemnity</th>\n",
       "      <th>Paid Expense</th>\n",
       "      <th>Reserves Total</th>\n",
       "      <th>Claim Recovery</th>\n",
       "      <th>Net Incurred</th>\n",
       "      <th>relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>AUTO PHYSICAL DAMAGE</td>\n",
       "      <td>SERVICE VEHICLE COLLISION</td>\n",
       "      <td>1510189190</td>\n",
       "      <td>20220818</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Kingsley Co.</td>\n",
       "      <td>OV was in the R through lane attempting to cha...</td>\n",
       "      <td>$509.73</td>\n",
       "      <td>$138.85</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$648.58</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>GARAGEKEEP ERS</td>\n",
       "      <td>GARAGE KEEPERS LIAB- COLL</td>\n",
       "      <td>1510188434</td>\n",
       "      <td>20220616</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Luckey John</td>\n",
       "      <td>Tech was driving customers vehicle out of serv...</td>\n",
       "      <td>$6,415.24</td>\n",
       "      <td>$143.67</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$6,558.91</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>GARAGEKEEP ERS</td>\n",
       "      <td>GARAGE KEEPERS LIAB- COMP</td>\n",
       "      <td>1510180666</td>\n",
       "      <td>20220216</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Henderson Joseph</td>\n",
       "      <td>vehicle caught on fire</td>\n",
       "      <td>$3,397.39</td>\n",
       "      <td>$113.80</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$3,511.19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GENERAL LIABILITY</td>\n",
       "      <td>GARAGE LIABILITY</td>\n",
       "      <td>GARAGE LIABILITY - BI</td>\n",
       "      <td>4620227025</td>\n",
       "      <td>20220818</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Gibb-Martin Shannon F</td>\n",
       "      <td>OV was in the R through lane attempting to cha...</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$41.60</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$41.60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GENERAL LIABILITY</td>\n",
       "      <td>GARAGE LIABILITY</td>\n",
       "      <td>GARAGE LIABILITY - PD</td>\n",
       "      <td>4620227025</td>\n",
       "      <td>20220818</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Gibb-Martin Shannon F</td>\n",
       "      <td>OV was in the R through lane attempting to cha...</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GENERAL LIABILITY</td>\n",
       "      <td>GARAGE LIABILITY</td>\n",
       "      <td>GARAGE LIAB MEDICAL PYMTS</td>\n",
       "      <td>4620221432</td>\n",
       "      <td>20220211</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Gensor Janet</td>\n",
       "      <td>Letter of representation received for Janet Ge...</td>\n",
       "      <td>$5,000.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$5,000.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GENERAL LIABILITY</td>\n",
       "      <td>GARAGE LIABILITY</td>\n",
       "      <td>GARAGE PREMISES BI</td>\n",
       "      <td>4620221432</td>\n",
       "      <td>20220211</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Gensor Janet</td>\n",
       "      <td>Letter of representation received for Janet Ge...</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>Claim Count:</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sum:</td>\n",
       "      <td>$15,322.36</td>\n",
       "      <td>$437.92</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$15,760.28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "1           Coverage          Sub Coverage         Val ID Description  \\\n",
       "2         AUTOMOBILE  AUTO PHYSICAL DAMAGE  SERVICE VEHICLE COLLISION   \n",
       "3         AUTOMOBILE        GARAGEKEEP ERS  GARAGE KEEPERS LIAB- COLL   \n",
       "4         AUTOMOBILE        GARAGEKEEP ERS  GARAGE KEEPERS LIAB- COMP   \n",
       "5  GENERAL LIABILITY      GARAGE LIABILITY      GARAGE LIABILITY - BI   \n",
       "6  GENERAL LIABILITY      GARAGE LIABILITY      GARAGE LIABILITY - PD   \n",
       "7  GENERAL LIABILITY      GARAGE LIABILITY  GARAGE LIAB MEDICAL PYMTS   \n",
       "8  GENERAL LIABILITY      GARAGE LIABILITY         GARAGE PREMISES BI   \n",
       "9                             Claim Count:                              \n",
       "\n",
       "1 Claim Number Date of Loss  Status          Claimant Name  \\\n",
       "2   1510189190     20220818  Closed           Kingsley Co.   \n",
       "3   1510188434     20220616  Closed            Luckey John   \n",
       "4   1510180666     20220216  Closed       Henderson Joseph   \n",
       "5   4620227025     20220818  Closed  Gibb-Martin Shannon F   \n",
       "6   4620227025     20220818  Closed  Gibb-Martin Shannon F   \n",
       "7   4620221432     20220211  Closed           Gensor Janet   \n",
       "8   4620221432     20220211  Closed           Gensor Janet   \n",
       "9            5                                               \n",
       "\n",
       "1                                 Accident Narrative Paid Indemnity  \\\n",
       "2  OV was in the R through lane attempting to cha...        $509.73   \n",
       "3  Tech was driving customers vehicle out of serv...      $6,415.24   \n",
       "4                             vehicle caught on fire      $3,397.39   \n",
       "5  OV was in the R through lane attempting to cha...          $0.00   \n",
       "6  OV was in the R through lane attempting to cha...          $0.00   \n",
       "7  Letter of representation received for Janet Ge...      $5,000.00   \n",
       "8  Letter of representation received for Janet Ge...          $0.00   \n",
       "9                                               Sum:     $15,322.36   \n",
       "\n",
       "1 Paid Expense Reserves Total Claim Recovery Net Incurred  relevant  \n",
       "2      $138.85          $0.00          $0.00      $648.58     False  \n",
       "3      $143.67          $0.00          $0.00    $6,558.91     False  \n",
       "4      $113.80          $0.00          $0.00    $3,511.19     False  \n",
       "5       $41.60          $0.00          $0.00       $41.60     False  \n",
       "6        $0.00          $0.00          $0.00        $0.00     False  \n",
       "7        $0.00          $0.00          $0.00    $5,000.00     False  \n",
       "8        $0.00          $0.00          $0.00        $0.00     False  \n",
       "9      $437.92          $0.00          $0.00   $15,760.28     False  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = table_dfs[2]\n",
    "\n",
    "# Set the first row as the column headers\n",
    "df1.columns = df1.iloc[0]  # Use the first row as header\n",
    "df1 = df1.drop(df1.index[0])  # Drop the first row from the DataFrame\n",
    "df1['relevant'] = df1['Claim Number'].isin(merged_output_frames['claim_number'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242b2236-11bb-4e2d-a85e-d9ee4f18b96a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gmft\n",
      "  Downloading gmft-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pypdfium2>=4 (from gmft)\n",
      "  Downloading pypdfium2-4.30.0-py3-none-macosx_11_0_arm64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: transformers>=4.35.2 in ./venv/lib/python3.12/site-packages (from gmft) (4.45.2)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.12/site-packages (from gmft) (2.4.1)\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.12/site-packages (from gmft) (11.0.0)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (from gmft) (2.2.3)\n",
      "Collecting matplotlib (from gmft)\n",
      "  Using cached matplotlib-3.9.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting tabulate (from gmft)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from transformers>=4.35.2->gmft) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./venv/lib/python3.12/site-packages (from transformers>=4.35.2->gmft) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.12/site-packages (from transformers>=4.35.2->gmft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from transformers>=4.35.2->gmft) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from transformers>=4.35.2->gmft) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers>=4.35.2->gmft) (2024.9.11)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from transformers>=4.35.2->gmft) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.12/site-packages (from transformers>=4.35.2->gmft) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./venv/lib/python3.12/site-packages (from transformers>=4.35.2->gmft) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.12/site-packages (from transformers>=4.35.2->gmft) (4.66.5)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->gmft)\n",
      "  Using cached contourpy-1.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->gmft)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->gmft)\n",
      "  Using cached fonttools-4.54.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (163 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->gmft)\n",
      "  Using cached kiwisolver-1.4.7-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->gmft)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.12/site-packages (from matplotlib->gmft) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas->gmft) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas->gmft) (2024.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.12/site-packages (from torch->gmft) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.12/site-packages (from torch->gmft) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch->gmft) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch->gmft) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.12/site-packages (from torch->gmft) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from torch->gmft) (75.2.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->gmft) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch->gmft) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->transformers>=4.35.2->gmft) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests->transformers>=4.35.2->gmft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests->transformers>=4.35.2->gmft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests->transformers>=4.35.2->gmft) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy->torch->gmft) (1.3.0)\n",
      "Downloading gmft-0.4.0-py3-none-any.whl (73 kB)\n",
      "Downloading pypdfium2-4.30.0-py3-none-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached matplotlib-3.9.2-cp312-cp312-macosx_11_0_arm64.whl (7.8 MB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached contourpy-1.3.0-cp312-cp312-macosx_11_0_arm64.whl (251 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.54.1-cp312-cp312-macosx_11_0_arm64.whl (2.3 MB)\n",
      "Using cached kiwisolver-1.4.7-cp312-cp312-macosx_11_0_arm64.whl (63 kB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: tabulate, pypdfium2, pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, gmft\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 gmft-0.4.0 kiwisolver-1.4.7 matplotlib-3.9.2 pyparsing-3.2.0 pypdfium2-4.30.0 tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gmft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "242a4664-231f-418c-ba36-27215eb61826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gmft.auto import CroppedTable, AutoTableDetector, AutoFormatConfig, AutoTableFormatter\n",
    "from gmft.pdf_bindings import PyPDFium2Document\n",
    "from gmft.detectors.common import CroppedTable\n",
    "\n",
    "detector = AutoTableDetector()\n",
    "config = AutoFormatConfig(verbosity=3)\n",
    "formatter = AutoTableFormatter(config=config)\n",
    "\n",
    "def ingest_pdf(pdf_path): # produces list[CroppedTable]\n",
    "    doc = PyPDFium2Document(pdf_path)\n",
    "    tables = []\n",
    "    for page in doc:\n",
    "        tables += detector.extract(page)\n",
    "    return tables, doc\n",
    "\n",
    "tables, doc = ingest_pdf(\"loss_runs/input/LenStolerTest.pdf\")\n",
    "doc.close() # once you're done with the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fa8194b-c009-4076-89b2-250f60d41c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d202c367-55e6-45a9-9bb1-dfc5e5de8295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pypdfium2\n",
      "Version: 4.30.0\n",
      "Summary: Python bindings to PDFium\n",
      "Home-page: https://github.com/pypdfium2-team/pypdfium2\n",
      "Author: pypdfium2-team\n",
      "Author-email: geisserml@gmail.com\n",
      "License: (Apache-2.0 OR BSD-3-Clause) AND LicenseRef-PdfiumThirdParty\n",
      "Location: /Users/benjaminmiller/UW-Madison_Undergraduate/Understory/venv/lib/python3.12/site-packages\n",
      "Requires: \n",
      "Required-by: gmft\n"
     ]
    }
   ],
   "source": [
    "!pip show pypdfium2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccddec8",
   "metadata": {},
   "source": [
    "## Upload PDF File to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6cf7880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully: File uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "# The API endpoint URL for your Lambda function\n",
    "API_URL = 'https://s5yeiaxtg6.execute-api.us-east-1.amazonaws.com/upload'\n",
    "\n",
    "# Function to call the Lambda API\n",
    "def upload_pdf_to_lambda(pdf_path, file_name):\n",
    "    # Read and encode the PDF file as base64\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        pdf_data = base64.b64encode(pdf_file.read()).decode('utf-8')\n",
    "\n",
    "    # Prepare the request payload\n",
    "    payload = {\n",
    "        \"pdf_data\": pdf_data,\n",
    "        \"file_name\": file_name\n",
    "    }\n",
    "\n",
    "    # Send POST request to the API Gateway endpoint\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            print(\"File uploaded successfully:\", response.text)\n",
    "        else:\n",
    "            print(\"Failed to upload file:\", response.text)\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error during request:\", e)\n",
    "\n",
    "# Usage example\n",
    "upload_pdf_to_lambda(\"loss_runs/input/Loss_Run___len stoler 8-24_page_5.pdf\", \"sample2.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python UnderstoryVenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
